# Thesis-HRL
## Abstract
Autonomous systems such as the robots sent on exploratory missions in space or underwater must have the ability to learn new things and recognize new objects after they have been deployed, and must take decisions during extended periods of time within a constantly changing environment. Lifelong machine learning is a key component for those systems and something we need in order to achieve real artificial general intelligence. By levering the power of hierarchical reinforcement learning we can create systems that can effectively and efficiently retain and reuse knowledge, a key aspect of lifelong machine learning. In this thesis we design a system that is able to learn new tasks throughout its lifetime, while still being able to remember how to solve tasks that it had already learnt. We create a simulated environment in which to test this new system and compare it to a more standard Q-learning approach. The empirical results confirm that the proposed system is able to function in the simulated environment and that, with more research involved, it could become a viable solution for the aforementioned real life systems.
